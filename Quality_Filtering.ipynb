{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01d9dd-ab62-4311-84ce-bfd1ede543c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "from collections import Counter, defaultdict\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ea6e5-f4d6-4df3-8f91-60e87cd2a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Path and Configuration\n",
    "\n",
    "BASE_PATH = \"Path\\\\to\\\\your\\\\dataset\"  # Specify the base path to your dataset here\n",
    "\n",
    "# Save all the datasets to the BASE_PATH folder\n",
    "# Path configuration based on your folder structure\n",
    "datasets_config = {\n",
    "    'APTOS2019': f'{BASE_PATH}/APTOS 2019',\n",
    "    'Diabetic_Retinopathy_V03': f'{BASE_PATH}/Diabetic Retinopathy_V03',\n",
    "    'IDRiD': f'{BASE_PATH}/IDRiD',\n",
    "    'Messidor2': f'{BASE_PATH}/Messidor 2',\n",
    "    'SUSTech_SYSU': f'{BASE_PATH}/SUSTech_SYSU',\n",
    "    'DeepDRiD': f'{BASE_PATH}/DeepDRiD'\n",
    "}\n",
    "\n",
    "# Other configuration settings\n",
    "OUTPUT_DIR = 'quality_review'\n",
    "RANDOM_SEED = 42\n",
    "N_SAMPLES_PER_DATASET = 300  # Number of images to sample for characterization\n",
    "\n",
    "print(\"Configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c183499-77f9-4247-bc5a-83b93c49441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Validate Dataset Paths\n",
    "\n",
    "def validate_dataset_paths(datasets_config):\n",
    "    valid_datasets = {}\n",
    "    \n",
    "    for name, path in datasets_config.items():\n",
    "        print(f\"\\nChecking {name}:\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Path does not exist\")\n",
    "            continue\n",
    "            \n",
    "        # Check for DR class folders (0, 1, 2, 3, 4)\n",
    "        dr_folders = []\n",
    "        image_counts = {}\n",
    "        \n",
    "        try:\n",
    "            for item in os.listdir(path):\n",
    "                item_path = os.path.join(path, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    if item.isdigit() and int(item) in [0, 1, 2, 3, 4]:\n",
    "                        dr_class = int(item)\n",
    "                        dr_folders.append(dr_class)\n",
    "                        image_extensions = ('.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.JPG', '.JPEG', '.PNG')\n",
    "                        image_count = 0\n",
    "                        for root, dirs, files in os.walk(item_path):\n",
    "                            for file in files:\n",
    "                                if file.lower().endswith(image_extensions):\n",
    "                                    image_count += 1\n",
    "                        image_counts[dr_class] = image_count\n",
    "            \n",
    "            if dr_folders:\n",
    "                dr_folders.sort()\n",
    "                total_images = sum(image_counts.values())\n",
    "                print(f\" Found DR classes: {dr_folders}\")\n",
    "                print(f\"Image counts per class:\")\n",
    "                dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "                for dr_class in dr_folders:\n",
    "                    dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "                    print(f\"     {dr_name} (Class {dr_class}): {image_counts[dr_class]:,} images\")\n",
    "                print(f\"Total images: {total_images:,}\")\n",
    "                \n",
    "                if total_images > 0:\n",
    "                    valid_datasets[name] = path\n",
    "                else:\n",
    "                    print(f\"No images found\")\n",
    "            else:\n",
    "                print(f\"No DR class folders (0,1,2,3,4) found\")\n",
    "                print(f\"Available folders: {[item for item in os.listdir(path) if os.path.isdir(os.path.join(path, item))]}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing path: {e}\")\n",
    "\n",
    "    return valid_datasets\n",
    "\n",
    "# Run validation\n",
    "valid_datasets = validate_dataset_paths(datasets_config)\n",
    "\n",
    "if not valid_datasets:\n",
    "    print(\"\\nNo valid datasets found!\")\n",
    "    print(\"1. Update BASE_PATH in cell [2] to your actual dataset location\")\n",
    "    print(\"2. Ensure your datasets have folders named 0, 1, 2, 3, 4 containing images\")\n",
    "else:\n",
    "    print(f\"\\n{len(valid_datasets)} Datasets loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b4678-122c-479c-859d-964c1a222d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Quality Identifier Class Definition\n",
    "\n",
    "class QualityIdentifier:\n",
    "    def __init__(self, output_dir='quality_review', random_seed=42):\n",
    "        self.output_dir = output_dir\n",
    "        self.dataset_profiles = {}\n",
    "        self.identification_results = []\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(f'{output_dir}/sample_images', exist_ok=True)\n",
    "        os.makedirs(f'{output_dir}/flagged_samples', exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Quality identification output directory: {output_dir}\")\n",
    "    \n",
    "    def extract_dr_label_from_path(self, image_path):\n",
    "        parts = image_path.split(os.sep)\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.isdigit() and int(part) in [0, 1, 2, 3, 4]:\n",
    "                return int(part)\n",
    "        \n",
    "        dr_patterns = {\n",
    "            'no_dr': 0, 'normal': 0, 'grade_0': 0, 'class_0': 0,\n",
    "            'mild': 1, 'grade_1': 1, 'class_1': 1,\n",
    "            'moderate': 2, 'grade_2': 2, 'class_2': 2,\n",
    "            'severe': 3, 'grade_3': 3, 'class_3': 3,\n",
    "            'proliferative': 4, 'grade_4': 4, 'class_4': 4\n",
    "        }\n",
    "        \n",
    "        for part in parts:\n",
    "            part_lower = part.lower()\n",
    "            if part_lower in dr_patterns:\n",
    "                return dr_patterns[part_lower]\n",
    "        return None\n",
    "    \n",
    "    def sample_images_strategically(self, dataset_path, n_samples):\n",
    "        all_images = []\n",
    "        class_images = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "        \n",
    "        image_extensions = ('.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.JPG', '.JPEG', '.PNG')\n",
    "        \n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(image_extensions):\n",
    "                    image_path = os.path.join(root, file)\n",
    "                    dr_class = self.extract_dr_label_from_path(image_path)\n",
    "                    if dr_class is not None:\n",
    "                        class_images[dr_class].append(image_path)\n",
    "        \n",
    "        for dr_class, images in class_images.items():\n",
    "            dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "            dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "            if images:\n",
    "                print(f\"    {dr_name}: {len(images)} images\")\n",
    "        \n",
    "        sampled_images = []\n",
    "        total_available = sum(len(images) for images in class_images.values())\n",
    "        \n",
    "        if total_available == 0:\n",
    "            print(\"No images found with valid DR labels\")\n",
    "            return []\n",
    "        \n",
    "        samples_per_class = max(1, n_samples // 5)\n",
    "        \n",
    "        for dr_class, images in class_images.items():\n",
    "            if images:\n",
    "                n_class_samples = min(samples_per_class, len(images))\n",
    "                sampled = np.random.choice(images, n_class_samples, replace=False)\n",
    "                sampled_images.extend(sampled)\n",
    "\n",
    "        print(f\"Selected {len(sampled_images)} stratified samples\")\n",
    "        return sampled_images\n",
    "    \n",
    "    def safe_calculate_brightness(self, image):\n",
    "        try:\n",
    "            brightness = float(np.mean(image))\n",
    "            return max(0.0, min(255.0, brightness))\n",
    "        except:\n",
    "            return 127.5\n",
    "    \n",
    "    def safe_calculate_contrast(self, image):\n",
    "        try:\n",
    "            contrast = float(np.std(image))\n",
    "            return max(0.0, contrast)\n",
    "        except:\n",
    "            return 50.0\n",
    "    \n",
    "    def safe_calculate_sharpness(self, gray):\n",
    "        try:\n",
    "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "            return max(0.0, float(laplacian_var))\n",
    "        except:\n",
    "            return 500.0\n",
    "    \n",
    "    def safe_calculate_entropy(self, gray):\n",
    "        try:\n",
    "            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "            hist = hist.flatten()\n",
    "            hist = hist[hist > 0]\n",
    "            if len(hist) == 0:\n",
    "                return 4.0\n",
    "            prob = hist / hist.sum()\n",
    "            entropy = float(-np.sum(prob * np.log2(prob)))\n",
    "            return max(0.0, min(8.0, entropy))\n",
    "        except:\n",
    "            return 4.0\n",
    "\n",
    "    def assess_vessel_visibility_improved(self, image):\n",
    "        try:\n",
    "            green = image[:, :, 1]\n",
    "            \n",
    "            kernels = {\n",
    "                'horizontal': np.array([[-1, -1, -1], [2, 2, 2], [-1, -1, -1]], dtype=np.float32),\n",
    "                'vertical': np.array([[-1, 2, -1], [-1, 2, -1], [-1, 2, -1]], dtype=np.float32),\n",
    "                'diagonal1': np.array([[2, -1, -1], [-1, 2, -1], [-1, -1, 2]], dtype=np.float32),\n",
    "                'diagonal2': np.array([[-1, -1, 2], [-1, 2, -1], [2, -1, -1]], dtype=np.float32)\n",
    "            }\n",
    "            \n",
    "            vessel_responses = []\n",
    "            for kernel in kernels.values():\n",
    "                filtered = cv2.filter2D(green, cv2.CV_32F, kernel)\n",
    "                vessel_responses.append(filtered)\n",
    "            \n",
    "            max_response = np.maximum.reduce(vessel_responses)\n",
    "            threshold = np.percentile(max_response, 95)\n",
    "            vessel_pixels = np.sum(max_response > threshold)\n",
    "            total_pixels = max_response.shape[0] * max_response.shape[1]\n",
    "            \n",
    "            visibility_score = vessel_pixels / max(total_pixels, 1)\n",
    "            return float(min(0.1, visibility_score))\n",
    "            \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def assess_optic_disc_visibility(self, image):\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            bright_pixels = np.sum(gray > np.percentile(gray, 90))\n",
    "            total_pixels = gray.shape[0] * gray.shape[1]\n",
    "            return float(bright_pixels / max(total_pixels, 1))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def assess_illumination_uniformity(self, gray):\n",
    "        try:\n",
    "            h, w = gray.shape\n",
    "            regions = []\n",
    "            \n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    start_y, end_y = i * h // 3, (i + 1) * h // 3\n",
    "                    start_x, end_x = j * w // 3, (j + 1) * w // 3\n",
    "                    region = gray[start_y:end_y, start_x:end_x]\n",
    "                    regions.append(np.mean(region))\n",
    "            \n",
    "            mean_intensity = np.mean(regions)\n",
    "            if mean_intensity > 0:\n",
    "                cv_score = np.std(regions) / mean_intensity\n",
    "                return float(max(0, min(1, 1 - cv_score)))\n",
    "            return 0.0\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def detect_extreme_pixels(self, gray):\n",
    "        try:\n",
    "            very_dark = np.sum(gray < 10)\n",
    "            very_bright = np.sum(gray > 245)\n",
    "            total_pixels = gray.shape[0] * gray.shape[1]\n",
    "            return float((very_dark + very_bright) / max(total_pixels, 1))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def assess_motion_blur(self, gray):\n",
    "        try:\n",
    "            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "            return float(np.mean(magnitude))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    def analyze_single_image(self, image_path):\n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                logger.warning(f\"File not found: {image_path}\")\n",
    "                return None\n",
    "                \n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                logger.warning(f\"Could not read image: {image_path}\")\n",
    "                return None\n",
    "            \n",
    "            if len(image.shape) != 3:\n",
    "                logger.warning(f\"Invalid image format: {image_path}\")\n",
    "                return None\n",
    "                \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            h, w = image.shape[:2]\n",
    "\n",
    "            if h < 100 or w < 100:\n",
    "                logger.warning(f\"Image too small ({w}x{h}): {image_path}\")\n",
    "                return None\n",
    "            \n",
    "            characteristics = {\n",
    "                'image_path': image_path,\n",
    "                'filename': os.path.basename(image_path),\n",
    "                'resolution': (w, h),\n",
    "                'file_size_mb': max(0.001, os.path.getsize(image_path) / (1024*1024)),\n",
    "                \n",
    "                'brightness': self.safe_calculate_brightness(image),\n",
    "                'contrast': self.safe_calculate_contrast(image),\n",
    "                'sharpness': self.safe_calculate_sharpness(gray),\n",
    "                'entropy': self.safe_calculate_entropy(gray),\n",
    "                \n",
    "                'color_balance': float(np.std([np.mean(image[:,:,0]), np.mean(image[:,:,1]), np.mean(image[:,:,2])])),\n",
    "                \n",
    "                'vessel_visibility': self.assess_vessel_visibility_improved(image),\n",
    "                'optic_disc_visibility': self.assess_optic_disc_visibility(image),\n",
    "                'illumination_uniformity': self.assess_illumination_uniformity(gray),\n",
    "                \n",
    "                'extreme_brightness_pixels': self.detect_extreme_pixels(gray),\n",
    "                'motion_blur_score': self.assess_motion_blur(gray)\n",
    "            }\n",
    "            return characteristics\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing {image_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"QualityIdentifier class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5. Parameter Validation\n",
    "\n",
    "class QualityParameters:\n",
    "    def __init__(self):\n",
    "        # Validated thresholds\n",
    "        self.BRIGHTNESS_BOUNDS = (10, 245)\n",
    "        self.BLACK_THRESHOLD = 30\n",
    "        self.VESSEL_PERCENTILE = 95\n",
    "        self.OPTIC_DISC_PERCENTILE = 90\n",
    "        \n",
    "        # Severity-specific adaptive thresholds\n",
    "        self.SEVERITY_PERCENTILES = {\n",
    "            0: 15,  # No DR - strictest\n",
    "            1: 12,  # Mild DR\n",
    "            2: 10,  # Moderate DR\n",
    "            3: 8,   # Severe DR\n",
    "            4: 5    # PDR - most relaxed\n",
    "        }\n",
    "        \n",
    "        # Quality composition weights\n",
    "        self.BASIC_WEIGHT = 0.3\n",
    "        self.MEDICAL_WEIGHT = 0.7\n",
    "        \n",
    "        # Minimum image requirements\n",
    "        self.MIN_RESOLUTION = (100, 100)\n",
    "        self.MIN_FILE_SIZE_MB = 0.001\n",
    "    \n",
    "    def validate_bounds(self):\n",
    "        assert 0 <= self.BRIGHTNESS_BOUNDS[0] < self.BRIGHTNESS_BOUNDS[1] <= 255\n",
    "        assert 0 < self.BLACK_THRESHOLD < 255\n",
    "        assert 0 < self.VESSEL_PERCENTILE <= 100\n",
    "        assert 0 < self.OPTIC_DISC_PERCENTILE <= 100\n",
    "        assert abs(self.BASIC_WEIGHT + self.MEDICAL_WEIGHT - 1.0) < 0.001\n",
    "        return True\n",
    "\n",
    "# Initialize and validate parameters\n",
    "quality_params = QualityParameters()\n",
    "quality_params.validate_bounds()\n",
    "print(\"Quality parameters validated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
