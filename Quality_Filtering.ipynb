{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01d9dd-ab62-4311-84ce-bfd1ede543c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "from collections import Counter, defaultdict\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ea6e5-f4d6-4df3-8f91-60e87cd2a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Path and Configuration\n",
    "\n",
    "BASE_PATH = r\"Path/to/your/dataset\"  # Specify the base path to your dataset here\n",
    "\n",
    "# Save all the datasets to the BASE_PATH folder\n",
    "# Path configuration based on your folder structure\n",
    "datasets_config = {\n",
    "    'APTOS2019': f'{BASE_PATH}/APTOS 2019',\n",
    "    'Diabetic_Retinopathy_V03': f'{BASE_PATH}/Diabetic Retinopathy_V03',\n",
    "    'IDRiD': f'{BASE_PATH}/IDRiD',\n",
    "    'Messidor2': f'{BASE_PATH}/Messidor 2',\n",
    "    'SUSTech_SYSU': f'{BASE_PATH}/SUSTech_SYSU',\n",
    "    'DeepDRiD': f'{BASE_PATH}/DeepDRiD'\n",
    "}\n",
    "\n",
    "# Other configuration settings\n",
    "OUTPUT_DIR = 'quality_review'\n",
    "RANDOM_SEED = 42\n",
    "N_SAMPLES_PER_DATASET = 300  # Number of images to sample for characterization\n",
    "\n",
    "print(\"Configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c183499-77f9-4247-bc5a-83b93c49441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Validate Dataset Paths\n",
    "\n",
    "def validate_dataset_paths(datasets_config):\n",
    "    valid_datasets = {}\n",
    "    \n",
    "    for name, path in datasets_config.items():\n",
    "        print(f\"\\nChecking {name}:\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Path does not exist\")\n",
    "            continue\n",
    "            \n",
    "        # Check for DR class folders (0, 1, 2, 3, 4)\n",
    "        dr_folders = []\n",
    "        image_counts = {}\n",
    "        \n",
    "        try:\n",
    "            for item in os.listdir(path):\n",
    "                item_path = os.path.join(path, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    if item.isdigit() and int(item) in [0, 1, 2, 3, 4]:\n",
    "                        dr_class = int(item)\n",
    "                        dr_folders.append(dr_class)\n",
    "                        image_extensions = ('.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.JPG', '.JPEG', '.PNG')\n",
    "                        image_count = 0\n",
    "                        for root, dirs, files in os.walk(item_path):\n",
    "                            for file in files:\n",
    "                                if file.lower().endswith(image_extensions):\n",
    "                                    image_count += 1\n",
    "                        image_counts[dr_class] = image_count\n",
    "            \n",
    "            if dr_folders:\n",
    "                dr_folders.sort()\n",
    "                total_images = sum(image_counts.values())\n",
    "                print(f\" Found DR classes: {dr_folders}\")\n",
    "                print(f\"Image counts per class:\")\n",
    "                dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "                for dr_class in dr_folders:\n",
    "                    dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "                    print(f\"     {dr_name} (Class {dr_class}): {image_counts[dr_class]:,} images\")\n",
    "                print(f\"Total images: {total_images:,}\")\n",
    "                \n",
    "                if total_images > 0:\n",
    "                    valid_datasets[name] = path\n",
    "                else:\n",
    "                    print(f\"No images found\")\n",
    "            else:\n",
    "                print(f\"No DR class folders (0,1,2,3,4) found\")\n",
    "                print(f\"Available folders: {[item for item in os.listdir(path) if os.path.isdir(os.path.join(path, item))]}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing path: {e}\")\n",
    "\n",
    "    return valid_datasets\n",
    "\n",
    "# Run validation\n",
    "valid_datasets = validate_dataset_paths(datasets_config)\n",
    "\n",
    "if not valid_datasets:\n",
    "    print(\"\\nNo valid datasets found!\")\n",
    "    print(\"1. Update BASE_PATH in cell [2] to your actual dataset location\")\n",
    "    print(\"2. Ensure your datasets have folders named 0, 1, 2, 3, 4 containing images\")\n",
    "else:\n",
    "    print(f\"\\n{len(valid_datasets)} Datasets loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b4678-122c-479c-859d-964c1a222d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Quality Identifier Class Definition\n",
    "\n",
    "class QualityIdentifier:\n",
    "    def __init__(self, output_dir='quality_review', random_seed=42):\n",
    "        self.output_dir = output_dir\n",
    "        self.dataset_profiles = {}\n",
    "        self.identification_results = []\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        # Create output directories\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(f'{output_dir}/sample_images', exist_ok=True)\n",
    "        os.makedirs(f'{output_dir}/flagged_samples', exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Quality identification output directory: {output_dir}\")\n",
    "    \n",
    "    def extract_dr_label_from_path(self, image_path):\n",
    "        parts = image_path.split(os.sep)\n",
    "        \n",
    "        # Method 1: Check for folder names that are DR classes (most common in your structure)\n",
    "        for part in parts:\n",
    "            if part.isdigit() and int(part) in [0, 1, 2, 3, 4]:\n",
    "                return int(part)\n",
    "        \n",
    "        # Method 2: Check for common DR folder naming patterns\n",
    "        dr_patterns = {\n",
    "            'no_dr': 0, 'normal': 0, 'grade_0': 0, 'class_0': 0,\n",
    "            'mild': 1, 'grade_1': 1, 'class_1': 1,\n",
    "            'moderate': 2, 'grade_2': 2, 'class_2': 2,\n",
    "            'severe': 3, 'grade_3': 3, 'class_3': 3,\n",
    "            'proliferative': 4, 'grade_4': 4, 'class_4': 4\n",
    "        }\n",
    "        \n",
    "        for part in parts:\n",
    "            part_lower = part.lower()\n",
    "            if part_lower in dr_patterns:\n",
    "                return dr_patterns[part_lower]\n",
    "        return None\n",
    "    \n",
    "    def sample_images_strategically(self, dataset_path, n_samples):\n",
    "        \"\"\"Sample images from all DR classes proportionally\"\"\"\n",
    "        all_images = []\n",
    "        class_images = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "        \n",
    "        # Collect all images by class\n",
    "        image_extensions = ('.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.JPG', '.JPEG', '.PNG')\n",
    "        \n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(image_extensions):\n",
    "                    image_path = os.path.join(root, file)\n",
    "                    dr_class = self.extract_dr_label_from_path(image_path)\n",
    "                    if dr_class is not None:\n",
    "                        class_images[dr_class].append(image_path)\n",
    "        \n",
    "        # Log class distribution\n",
    "        for dr_class, images in class_images.items():\n",
    "            dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "            dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "            if images:\n",
    "                print(f\"    {dr_name}: {len(images)} images\")\n",
    "        \n",
    "        # Sample proportionally from each class\n",
    "        sampled_images = []\n",
    "        total_available = sum(len(images) for images in class_images.values())\n",
    "        \n",
    "        if total_available == 0:\n",
    "            print(\"No images found with valid DR labels\")\n",
    "            return []\n",
    "        \n",
    "        samples_per_class = max(1, n_samples // 5)\n",
    "        \n",
    "        for dr_class, images in class_images.items():\n",
    "            if images:\n",
    "                n_class_samples = min(samples_per_class, len(images))\n",
    "                sampled = np.random.choice(images, n_class_samples, replace=False)\n",
    "                sampled_images.extend(sampled)\n",
    "\n",
    "        print(f\"Selected {len(sampled_images)} stratified samples\")\n",
    "        return sampled_images\n",
    "    \n",
    "    # Calculate shannon entropy\n",
    "    def calculate_entropy(self, image):\n",
    "        try:\n",
    "            hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "            hist = hist.flatten()\n",
    "            hist = hist[hist > 0]\n",
    "            if len(hist) == 0:\n",
    "                return 0.0\n",
    "            prob = hist / hist.sum()\n",
    "            return float(-np.sum(prob * np.log2(prob)))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # Vessel visibility assessment\n",
    "    def assess_vessel_visibility(self, image):\n",
    "        try:\n",
    "            green = image[:, :, 1]\n",
    "            # Vessel enhancement filter\n",
    "            kernel = np.array([[-1, -1, -1], [2, 2, 2], [-1, -1, -1]], dtype=np.float32)\n",
    "            filtered = cv2.filter2D(green, cv2.CV_32F, kernel)\n",
    "            vessel_pixels = np.sum(filtered > np.percentile(filtered, 98))\n",
    "            total_pixels = filtered.shape[0] * filtered.shape[1]\n",
    "            return float(vessel_pixels / max(total_pixels, 1))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # Optic disc visibility assessment\n",
    "    def assess_optic_disc_visibility(self, image):\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            bright_pixels = np.sum(gray > np.percentile(gray, 95))\n",
    "            total_pixels = gray.shape[0] * gray.shape[1]\n",
    "            return float(bright_pixels / max(total_pixels, 1))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # Illumination uniformity assessment\n",
    "    def assess_illumination_uniformity(self, gray):\n",
    "        try:\n",
    "            h, w = gray.shape\n",
    "            regions = []\n",
    "            \n",
    "            # Divide into 3x3 grid\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    start_y, end_y = i * h // 3, (i + 1) * h // 3\n",
    "                    start_x, end_x = j * w // 3, (j + 1) * w // 3\n",
    "                    region = gray[start_y:end_y, start_x:end_x]\n",
    "                    regions.append(np.mean(region))\n",
    "            \n",
    "            mean_intensity = np.mean(regions)\n",
    "            if mean_intensity > 0:\n",
    "                cv_score = np.std(regions) / mean_intensity\n",
    "                return float(max(0, 1 - cv_score))\n",
    "            return 0.0\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # Black border detection\n",
    "    def detect_black_borders(self, gray):\n",
    "        try:\n",
    "            h, w = gray.shape\n",
    "            border_thickness = min(50, h//10, w//10)\n",
    "            \n",
    "            if border_thickness < 1:\n",
    "                return False\n",
    "            \n",
    "            top_border = np.mean(gray[:border_thickness, :])\n",
    "            bottom_border = np.mean(gray[-border_thickness:, :])\n",
    "            left_border = np.mean(gray[:, :border_thickness])\n",
    "            right_border = np.mean(gray[:, -border_thickness:])\n",
    "            \n",
    "            # How dark to consider a border as black\n",
    "            black_threshold = 30\n",
    "            return any(border < black_threshold for border in [top_border, bottom_border, left_border, right_border])\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    # Extreme pixel detection\n",
    "    def detect_extreme_pixels(self, gray):\n",
    "        try:\n",
    "            very_dark = np.sum(gray < 10)\n",
    "            very_bright = np.sum(gray > 245)\n",
    "            total_pixels = gray.shape[0] * gray.shape[1]\n",
    "            return float((very_dark + very_bright) / max(total_pixels, 1))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # Motion blur assessment\n",
    "    def assess_motion_blur(self, gray):\n",
    "        try:\n",
    "            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "            return float(np.mean(magnitude))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    # Single image analysis\n",
    "    def analyze_single_image(self, image_path):\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                return None\n",
    "            \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            h, w = image.shape[:2]\n",
    "\n",
    "            # Checking for minimum size requirements\n",
    "            if h < 50 or w < 50:\n",
    "                return None\n",
    "            \n",
    "            characteristics = {\n",
    "                'image_path': image_path,\n",
    "                'filename': os.path.basename(image_path),\n",
    "                'resolution': (w, h),\n",
    "                'file_size_mb': os.path.getsize(image_path) / (1024*1024),\n",
    "                \n",
    "                # Basic quality metrics\n",
    "                'brightness': float(np.mean(image)),\n",
    "                'contrast': float(np.std(image)),\n",
    "                'sharpness': float(cv2.Laplacian(gray, cv2.CV_64F).var()),\n",
    "                'entropy': self.calculate_entropy(gray),\n",
    "                \n",
    "                # Color analysis (important for different cameras/ethnicities)\n",
    "                'red_mean': float(np.mean(image[:,:,2])),\n",
    "                'green_mean': float(np.mean(image[:,:,1])),\n",
    "                'blue_mean': float(np.mean(image[:,:,0])),\n",
    "                'color_balance': float(np.std([np.mean(image[:,:,0]), np.mean(image[:,:,1]), np.mean(image[:,:,2])])),\n",
    "                \n",
    "                # Internal structure visibility\n",
    "                'vessel_visibility': self.assess_vessel_visibility(image),\n",
    "                'optic_disc_visibility': self.assess_optic_disc_visibility(image),\n",
    "                'illumination_uniformity': self.assess_illumination_uniformity(gray),\n",
    "                \n",
    "                # Potential artifact detection\n",
    "                'has_black_borders': self.detect_black_borders(gray),\n",
    "                'extreme_brightness_pixels': self.detect_extreme_pixels(gray),\n",
    "                'motion_blur_score': self.assess_motion_blur(gray)\n",
    "            }\n",
    "            return characteristics\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "print(\"QualityIdentifier class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaace56-0745-4186-ab8a-7ddd39833f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Initialize Quality Identifier\n",
    "\n",
    "# Proceed if we have datasets are validated in above cells\n",
    "if valid_datasets:\n",
    "    identifier = QualityIdentifier(\n",
    "        output_dir=OUTPUT_DIR, \n",
    "        random_seed=RANDOM_SEED\n",
    "    )\n",
    "    print(\"QualityIdentifier initialized!\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"Cannot initialize - no valid datasets found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe32452-0520-49ce-b7b8-e312f5aeaa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Dataset Characterization & Adaptive Thresholding\n",
    "\n",
    "# Characterization function\n",
    "def characterize_dataset(identifier, dataset_path, dataset_name, n_samples=300):\n",
    "    print(f\"Characterizing {dataset_name}...\")\n",
    "    \n",
    "    sample_images = identifier.sample_images_strategically(dataset_path, n_samples)\n",
    "    \n",
    "    if not sample_images:\n",
    "        print(f\"No images found in {dataset_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Analyzing {len(sample_images)} sample images...\")\n",
    "    \n",
    "    # Analyze characteristics with progress updates\n",
    "    characteristics = []\n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        if i % 50 == 0 and i > 0:\n",
    "            print(f\"    Progress: {i}/{len(sample_images)} ({i/len(sample_images)*100:.1f}%)\")\n",
    "        char = identifier.analyze_single_image(img_path)\n",
    "        if char:\n",
    "            characteristics.append(char)  \n",
    "\n",
    "        # Memory management\n",
    "        if i % 100 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "    if not characteristics:\n",
    "        print(f\"No valid characteristics extracted from {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Analyzed {len(characteristics)} valid images\")\n",
    "\n",
    "    # Calculate dataset profile\n",
    "    profile = calculate_dataset_profile(dataset_name, characteristics)\n",
    "    \n",
    "    # Save sample images for review\n",
    "    save_sample_images(identifier, sample_images[:20], dataset_name)\n",
    "    return profile\n",
    "\n",
    "# Calculate dataset profile\n",
    "def calculate_dataset_profile(dataset_name, characteristics):\n",
    "    profile = {\n",
    "        'dataset_name': dataset_name,\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'n_samples_analyzed': len(characteristics),\n",
    "        'characteristics_stats': {},\n",
    "        'adaptive_thresholds': {}\n",
    "    }\n",
    "    \n",
    "    numeric_keys = [key for key in characteristics[0].keys() \n",
    "                   if key not in ['image_path', 'filename', 'resolution']]\n",
    "    \n",
    "    for key in numeric_keys:\n",
    "        # Get raw values, filtering out None\n",
    "        raw_values = [char[key] for char in characteristics if char[key] is not None]\n",
    "        \n",
    "        # Convert values, handling booleans and ensuring numeric types\n",
    "        values = []\n",
    "        for val in raw_values:\n",
    "            if isinstance(val, bool):\n",
    "                values.append(float(val))  # True -> 1.0, False -> 0.0\n",
    "            elif isinstance(val, (int, float)):\n",
    "                values.append(float(val))\n",
    "            else:\n",
    "                # Skip non-numeric, non-boolean values\n",
    "                continue\n",
    "        \n",
    "        if values:\n",
    "            profile['characteristics_stats'][key] = {\n",
    "                'mean': float(np.mean(values)),\n",
    "                'std': float(np.std(values)),\n",
    "                'min': float(np.min(values)),\n",
    "                'max': float(np.max(values)),\n",
    "                'percentiles': {\n",
    "                    '5': float(np.percentile(values, 5)),\n",
    "                    '10': float(np.percentile(values, 10)),\n",
    "                    '25': float(np.percentile(values, 25)),\n",
    "                    '50': float(np.percentile(values, 50)),\n",
    "                    '75': float(np.percentile(values, 75)),\n",
    "                    '90': float(np.percentile(values, 90)),\n",
    "                    '95': float(np.percentile(values, 95))\n",
    "                }\n",
    "            }\n",
    "\n",
    "    # Adaptive removal thresholds calculation\n",
    "    # Define adaptive removal percentiles based on DR severity\n",
    "    removal_percentiles = {\n",
    "        0: 15,\n",
    "        1: 12,\n",
    "        2: 10,\n",
    "        3: 8,\n",
    "        4: 5\n",
    "    }\n",
    "    \n",
    "    # Calculate combined quality scores for threshold calculation\n",
    "    quality_scores = []\n",
    "    for char in characteristics:\n",
    "        # Safely get and normalize metrics with error handling\n",
    "        try:\n",
    "            # Convert boolean values to float if needed ( Edge case scenarios)\n",
    "            brightness = float(char['brightness']) if char['brightness'] is not None else 127.5\n",
    "            contrast = float(char['contrast']) if char['contrast'] is not None else 50.0\n",
    "            sharpness = float(char['sharpness']) if char['sharpness'] is not None else 500.0\n",
    "            entropy = float(char['entropy']) if char['entropy'] is not None else 4.0\n",
    "            illumination_uniformity = float(char['illumination_uniformity']) if char['illumination_uniformity'] is not None else 0.5\n",
    "            vessel_visibility = float(char['vessel_visibility']) if char['vessel_visibility'] is not None else 0.1\n",
    "            optic_disc_visibility = float(char['optic_disc_visibility']) if char['optic_disc_visibility'] is not None else 0.1\n",
    "            \n",
    "            # Normalize metrics\n",
    "            brightness_norm = min(1.0, max(0.0, brightness / 255.0))\n",
    "            contrast_norm = min(1.0, max(0.0, contrast / 100.0))\n",
    "            sharpness_norm = min(1.0, max(0.0, sharpness / 1000.0))\n",
    "            entropy_norm = min(1.0, max(0.0, entropy / 8.0))\n",
    "            \n",
    "            basic_quality = np.mean([brightness_norm, contrast_norm, sharpness_norm, entropy_norm])\n",
    "            \n",
    "            medical_quality = np.mean([\n",
    "                illumination_uniformity,\n",
    "                min(1.0, vessel_visibility * 10),\n",
    "                min(1.0, optic_disc_visibility * 10)\n",
    "            ])\n",
    "            \n",
    "            combined_quality = 0.3 * basic_quality + 0.7 * medical_quality\n",
    "            quality_scores.append(combined_quality)\n",
    "        except (TypeError, ValueError) as e:\n",
    "            # If there's an error with any characteristic, use a default quality score\n",
    "            print(f\"Warning: Error calculating quality score for image, using default: {e}\")\n",
    "            quality_scores.append(0.3)  # Default low quality score\n",
    "    \n",
    "    # Set percentile-based thresholds\n",
    "    for dr_severity, percentile in removal_percentiles.items():\n",
    "        try:\n",
    "            threshold = np.percentile(quality_scores, percentile) if quality_scores else 0.3\n",
    "            profile['adaptive_thresholds'][dr_severity] = float(threshold)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating threshold for DR severity {dr_severity}: {e}\")\n",
    "            profile['adaptive_thresholds'][dr_severity] = 0.3  # Default threshold\n",
    "\n",
    "    return profile\n",
    "\n",
    "# Save sample images for visual review\n",
    "def save_sample_images(identifier, sample_paths, dataset_name):\n",
    "    sample_dir = f'{identifier.output_dir}/sample_images/{dataset_name}'\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    \n",
    "    copied_count = 0\n",
    "    for i, img_path in enumerate(sample_paths):\n",
    "        try:\n",
    "            dst_path = f'{sample_dir}/sample_{i:02d}_{os.path.basename(img_path)}'\n",
    "            shutil.copy2(img_path, dst_path)\n",
    "            copied_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error copying sample {img_path}: {e}\")\n",
    "\n",
    "    print(f\"Saved {copied_count} sample images to {sample_dir}\")\n",
    "\n",
    "# Run characterization for all valid datasets\n",
    "if valid_datasets:\n",
    "    dataset_profiles = {}\n",
    "    \n",
    "    for dataset_name, dataset_path in valid_datasets.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        profile = characterize_dataset(identifier, dataset_path, dataset_name, N_SAMPLES_PER_DATASET)\n",
    "        if profile:\n",
    "            dataset_profiles[dataset_name] = profile\n",
    "            identifier.dataset_profiles[dataset_name] = profile\n",
    "            print(f\"{dataset_name} characterized\")\n",
    "\n",
    "            # Show key metrics\n",
    "            stats = profile['characteristics_stats']\n",
    "            print(f\"Key metrics (mean ± std):\")\n",
    "            if 'brightness' in stats:\n",
    "                print(f\"      Brightness: {stats['brightness']['mean']:.1f} ± {stats['brightness']['std']:.1f}\")\n",
    "            if 'sharpness' in stats:\n",
    "                print(f\"      Sharpness: {stats['sharpness']['mean']:.1f} ± {stats['sharpness']['std']:.1f}\")\n",
    "            if 'illumination_uniformity' in stats:\n",
    "                print(f\"      Illumination uniformity: {stats['illumination_uniformity']['mean']:.3f} ± {stats['illumination_uniformity']['std']:.3f}\")\n",
    "        else:\n",
    "            print(f\"Failed characterization {dataset_name}\")\n",
    "\n",
    "    print(f\"\\nCharacterization complete! Profiles created for {len(dataset_profiles)} datasets.\")\n",
    "else:\n",
    "    print(\"Skipping characterization - no valid datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe4d72-7516-431c-90d0-23b9e1290811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Quality Issue Identification\n",
    "\n",
    "# Assess image quality against dataset profile\n",
    "def assess_image_quality(characteristics, profile, dr_severity):\n",
    "    \n",
    "    # Normalize characteristics relative to dataset\n",
    "    normalized_scores = {}\n",
    "    char_stats = profile['characteristics_stats']\n",
    "    \n",
    "    # Normalize key metrics\n",
    "    key_metrics = ['brightness', 'contrast', 'sharpness', 'entropy', \n",
    "                  'illumination_uniformity', 'vessel_visibility', 'optic_disc_visibility']\n",
    "    \n",
    "    for metric in key_metrics:\n",
    "        if metric in char_stats and metric in characteristics:\n",
    "            stats = char_stats[metric]\n",
    "            value = characteristics[metric]\n",
    "            \n",
    "            # Z-score normalization, then convert to 0-1 scale\n",
    "            if stats['std'] > 0:\n",
    "                z_score = (value - stats['mean']) / stats['std']\n",
    "                normalized = max(0, min(1, (z_score + 3) / 6))  # Map [-3,3] to [0,1]\n",
    "            else:\n",
    "                normalized = 0.5\n",
    "            \n",
    "            normalized_scores[metric] = normalized\n",
    "    \n",
    "    # Calculate combined quality score\n",
    "    basic_metrics = ['brightness', 'contrast', 'sharpness', 'entropy']\n",
    "    medical_metrics = ['illumination_uniformity', 'vessel_visibility', 'optic_disc_visibility']\n",
    "    \n",
    "    basic_score = np.mean([normalized_scores.get(m, 0.5) for m in basic_metrics])\n",
    "    medical_score = np.mean([normalized_scores.get(m, 0.5) for m in medical_metrics])\n",
    "    \n",
    "    overall_score = 0.3 * basic_score + 0.7 * medical_score\n",
    "    \n",
    "    # Get threshold for this DR severity\n",
    "    threshold = profile['adaptive_thresholds'].get(dr_severity, 0.3)\n",
    "    \n",
    "    # Determine removal reasons\n",
    "    removal_reasons = []\n",
    "    \n",
    "    # Check for severe quality issues\n",
    "    if characteristics['sharpness'] < char_stats['sharpness']['percentiles']['5']:\n",
    "        removal_reasons.append('extremely_blurry')\n",
    "    \n",
    "    if characteristics['brightness'] < 20 or characteristics['brightness'] > 240:\n",
    "        removal_reasons.append('extreme_brightness')\n",
    "    \n",
    "    if characteristics['illumination_uniformity'] < 0.1:\n",
    "        removal_reasons.append('poor_illumination')\n",
    "    \n",
    "    if characteristics['vessel_visibility'] < char_stats['vessel_visibility']['percentiles']['5']:\n",
    "        removal_reasons.append('poor_vessel_visibility')\n",
    "    \n",
    "    if characteristics['extreme_brightness_pixels'] > 0.3:\n",
    "        removal_reasons.append('too_many_extreme_pixels')\n",
    "    \n",
    "    if characteristics['file_size_mb'] < 0.1:\n",
    "        removal_reasons.append('file_too_small')\n",
    "    \n",
    "    # Resolution check\n",
    "    w, h = characteristics['resolution']\n",
    "    if w < 224 or h < 224:\n",
    "        removal_reasons.append('resolution_too_low')\n",
    "    \n",
    "    # Make recommendation\n",
    "    if len(removal_reasons) >= 2:  # Multiple severe issues\n",
    "        action = 'REMOVE'\n",
    "        confidence = 'HIGH'\n",
    "    elif overall_score < threshold:\n",
    "        action = 'REMOVE'\n",
    "        confidence = 'MEDIUM'\n",
    "    else:\n",
    "        action = 'KEEP'\n",
    "        confidence = 'HIGH' if overall_score > threshold + 0.1 else 'MEDIUM'\n",
    "    \n",
    "    return {\n",
    "        'overall_score': overall_score,\n",
    "        'threshold': threshold,\n",
    "        'action': action,\n",
    "        'reasons': removal_reasons,\n",
    "        'confidence': confidence,\n",
    "        'normalized_scores': normalized_scores\n",
    "    }\n",
    "\n",
    "# Identify images with quality issues\n",
    "def identify_quality_issues(identifier, dataset_path, dataset_name, profile):\n",
    "    print(f\"Identifying quality issues in {dataset_name}\")\n",
    "    \n",
    "    results = []\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.JPG', '.JPEG', '.PNG')\n",
    "    \n",
    "    # Count total images first\n",
    "    total_images = 0\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(image_extensions):\n",
    "                image_path = os.path.join(root, file)\n",
    "                dr_severity = identifier.extract_dr_label_from_path(image_path)\n",
    "                if dr_severity is not None:\n",
    "                    total_images += 1\n",
    "    \n",
    "    print(f\"  Found {total_images:,} images to analyze\")\n",
    "    \n",
    "    # Process images\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(image_extensions):\n",
    "                image_path = os.path.join(root, file)\n",
    "                dr_severity = identifier.extract_dr_label_from_path(image_path)\n",
    "                \n",
    "                if dr_severity is None:\n",
    "                    continue\n",
    "                \n",
    "                # Analyze image\n",
    "                characteristics = identifier.analyze_single_image(image_path)\n",
    "                if not characteristics:\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # Calculate quality scores\n",
    "                quality_assessment = assess_image_quality(characteristics, profile, dr_severity)\n",
    "                \n",
    "                # Create result record\n",
    "                result = {\n",
    "                    'dataset': dataset_name,\n",
    "                    'image_path': image_path,\n",
    "                    'filename': file,\n",
    "                    'dr_severity': dr_severity,\n",
    "                    'overall_quality_score': quality_assessment['overall_score'],\n",
    "                    'threshold_used': quality_assessment['threshold'],\n",
    "                    'recommended_action': quality_assessment['action'],\n",
    "                    'removal_reasons': quality_assessment['reasons'],\n",
    "                    'confidence': quality_assessment['confidence']\n",
    "                }\n",
    "                \n",
    "                # Add detailed scores\n",
    "                result.update(characteristics)\n",
    "                result.update({f'normalized_{k}': v for k, v in quality_assessment['normalized_scores'].items()})\n",
    "                \n",
    "                results.append(result)\n",
    "                processed_count += 1\n",
    "                \n",
    "                if processed_count % 1000 == 0:\n",
    "                    progress = processed_count / total_images * 100 if total_images > 0 else 0\n",
    "                    print(f\"    Progress: {processed_count:,}/{total_images:,} ({progress:.1f}%)\")\n",
    "                    gc.collect()  # Memory management\n",
    "    \n",
    "    print(f\"  Analysis completed: {processed_count:,} images processed\")\n",
    "    if error_count > 0:\n",
    "        print(f\"  Images with errors: {error_count}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run quality issue identification\n",
    "if valid_datasets and dataset_profiles:\n",
    "    print(\"Starting quality issue identification\")\n",
    "    all_results = []\n",
    "    \n",
    "    for dataset_name, profile in dataset_profiles.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        dataset_path = valid_datasets[dataset_name]\n",
    "        results = identify_quality_issues(identifier, dataset_path, dataset_name, profile)\n",
    "        all_results.extend(results)\n",
    "        \n",
    "        # Show preliminary stats for this dataset\n",
    "        flagged = [r for r in results if r['recommended_action'] == 'REMOVE']\n",
    "        flagged_count = len(flagged)\n",
    "        total_count = len(results)\n",
    "        removal_rate = flagged_count / total_count * 100 if total_count > 0 else 0\n",
    "        \n",
    "        print(f\"  Results for {dataset_name}:\")\n",
    "        print(f\"     Total analyzed: {total_count:,}\")\n",
    "        print(f\"     Flagged for removal: {flagged_count:,} ({removal_rate:.1f}%)\")\n",
    "        \n",
    "        # Show breakdown by DR class\n",
    "        dr_stats = defaultdict(lambda: {'total': 0, 'flagged': 0})\n",
    "        for result in results:\n",
    "            dr_class = result['dr_severity']\n",
    "            dr_stats[dr_class]['total'] += 1\n",
    "            if result['recommended_action'] == 'REMOVE':\n",
    "                dr_stats[dr_class]['flagged'] += 1\n",
    "        \n",
    "        print(f\"     DR class breakdown:\")\n",
    "        dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "        for dr_class in sorted(dr_stats.keys()):\n",
    "            stats = dr_stats[dr_class]\n",
    "            class_removal_rate = stats['flagged'] / stats['total'] * 100 if stats['total'] > 0 else 0\n",
    "            dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "            print(f\"       {dr_name}: {stats['flagged']:,}/{stats['total']:,} ({class_removal_rate:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nQuality identification completed: {len(all_results):,} images analyzed across all datasets\")\n",
    "else:\n",
    "    print(\"Quality identification skipped - no valid datasets or profiles available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59dd37e-843e-419f-9faa-f75c714c640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create Flagged Samples\n",
    "\n",
    "# Create visual samples of flagged images for manual review\n",
    "def create_flagged_samples(identifier, results, n_samples_per_dataset=20):\n",
    "    print(\"Creating flagged image samples for review\")\n",
    "   \n",
    "    # Group by dataset\n",
    "    by_dataset = {}\n",
    "    for result in results:\n",
    "        dataset = result['dataset']\n",
    "        if dataset not in by_dataset:\n",
    "            by_dataset[dataset] = []\n",
    "        by_dataset[dataset].append(result)\n",
    "   \n",
    "    total_samples_created = 0\n",
    "   \n",
    "    for dataset_name, dataset_results in by_dataset.items():\n",
    "        print(f\"\\n  Processing {dataset_name}\")\n",
    "       \n",
    "        # Get flagged images\n",
    "        flagged = [r for r in dataset_results if r['recommended_action'] == 'REMOVE']\n",
    "       \n",
    "        if not flagged:\n",
    "            print(f\"    No flagged images found\")\n",
    "            continue\n",
    "       \n",
    "        print(f\"    Found {len(flagged)} flagged images\")\n",
    "       \n",
    "        # Sample different types of issues\n",
    "        sample_dir = f'{identifier.output_dir}/flagged_samples/{dataset_name}'\n",
    "        os.makedirs(sample_dir, exist_ok=True)\n",
    "       \n",
    "        # Group by removal reasons\n",
    "        by_reason = {}\n",
    "        for result in flagged:\n",
    "            for reason in result['removal_reasons']:\n",
    "                if reason not in by_reason:\n",
    "                    by_reason[reason] = []\n",
    "                by_reason[reason].append(result)\n",
    "       \n",
    "        print(f\"    Issue types found: {list(by_reason.keys())}\")\n",
    "       \n",
    "        # Sample from each reason category\n",
    "        samples_copied = 0\n",
    "        for reason, reason_results in by_reason.items():\n",
    "            reason_samples = min(5, len(reason_results), n_samples_per_dataset - samples_copied)\n",
    "            if reason_samples <= 0:\n",
    "                continue\n",
    "           \n",
    "            # Sort by confidence and take most confident removals\n",
    "            reason_results.sort(key=lambda x: x['overall_quality_score'])\n",
    "           \n",
    "            for i, result in enumerate(reason_results[:reason_samples]):\n",
    "                try:\n",
    "                    src_path = result['image_path']\n",
    "                    dst_filename = f'{reason}_{i:02d}_{result[\"filename\"]}'\n",
    "                    dst_path = os.path.join(sample_dir, dst_filename)\n",
    "                    shutil.copy2(src_path, dst_path)\n",
    "                    samples_copied += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error copying flagged sample {src_path}: {e}\")\n",
    "       \n",
    "        print(f\"    Created {samples_copied} flagged samples\")\n",
    "        total_samples_created += samples_copied\n",
    "   \n",
    "    print(f\"\\nTotal flagged samples created: {total_samples_created}\")\n",
    "\n",
    "# Run flagged sample creation\n",
    "if 'all_results' in locals() and all_results:\n",
    "    create_flagged_samples(identifier, all_results)\n",
    "else:\n",
    "    print(\"Flagged sample creation skipped - no results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e0b85-fab8-46ef-940b-651da37b3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Generate Comprehensive Report\n",
    "\n",
    "# Generate comprehensive identification report with statistics and recommendations\n",
    "def generate_identification_report(all_results):\n",
    "    print(\"Generating identification report\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_images = len(df)\n",
    "    flagged_for_removal = len(df[df['recommended_action'] == 'REMOVE'])\n",
    "    removal_rate = flagged_for_removal / total_images if total_images > 0 else 0\n",
    "    \n",
    "    report = {\n",
    "        'analysis_summary': {\n",
    "            'total_images_analyzed': total_images,\n",
    "            'images_flagged_for_removal': flagged_for_removal,\n",
    "            'overall_removal_rate': removal_rate,\n",
    "            'analysis_date': datetime.now().isoformat()\n",
    "        },\n",
    "        'dataset_breakdown': {},\n",
    "        'removal_reasons_summary': {},\n",
    "        'quality_score_statistics': {},\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # Per-dataset breakdown\n",
    "    for dataset in df['dataset'].unique():\n",
    "        dataset_data = df[df['dataset'] == dataset]\n",
    "        dataset_flagged = len(dataset_data[dataset_data['recommended_action'] == 'REMOVE'])\n",
    "        dataset_total = len(dataset_data)\n",
    "        \n",
    "        # Per-class breakdown\n",
    "        class_breakdown = {}\n",
    "        for dr_class in range(5):\n",
    "            class_data = dataset_data[dataset_data['dr_severity'] == dr_class]\n",
    "            if len(class_data) > 0:\n",
    "                class_flagged = len(class_data[class_data['recommended_action'] == 'REMOVE'])\n",
    "                class_breakdown[dr_class] = {\n",
    "                    'total': len(class_data),\n",
    "                    'flagged': class_flagged,\n",
    "                    'removal_rate': class_flagged / len(class_data)\n",
    "                }\n",
    "        \n",
    "        report['dataset_breakdown'][dataset] = {\n",
    "            'total_images': dataset_total,\n",
    "            'flagged_images': dataset_flagged,\n",
    "            'removal_rate': dataset_flagged / dataset_total if dataset_total > 0 else 0,\n",
    "            'class_breakdown': class_breakdown,\n",
    "            'avg_quality_score': float(dataset_data['overall_quality_score'].mean()),\n",
    "            'quality_score_std': float(dataset_data['overall_quality_score'].std())\n",
    "        }\n",
    "    \n",
    "    # Removal reasons summary\n",
    "    all_reasons = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['recommended_action'] == 'REMOVE':\n",
    "            all_reasons.extend(row['removal_reasons'])\n",
    "    \n",
    "    reason_counts = Counter(all_reasons)\n",
    "    report['removal_reasons_summary'] = dict(reason_counts)\n",
    "    \n",
    "    # Quality score statistics\n",
    "    report['quality_score_statistics'] = {\n",
    "        'mean': float(df['overall_quality_score'].mean()),\n",
    "        'std': float(df['overall_quality_score'].std()),\n",
    "        'min': float(df['overall_quality_score'].min()),\n",
    "        'max': float(df['overall_quality_score'].max()),\n",
    "        'percentiles': {\n",
    "            '10': float(df['overall_quality_score'].quantile(0.1)),\n",
    "            '25': float(df['overall_quality_score'].quantile(0.25)),\n",
    "            '50': float(df['overall_quality_score'].quantile(0.5)),\n",
    "            '75': float(df['overall_quality_score'].quantile(0.75)),\n",
    "            '90': float(df['overall_quality_score'].quantile(0.9))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Generate recommendations\n",
    "    if removal_rate > 0.4:\n",
    "        report['recommendations'].append(\"HIGH removal rate detected. Consider relaxing quality thresholds.\")\n",
    "    \n",
    "    if removal_rate < 0.05:\n",
    "        report['recommendations'].append(\"LOW removal rate detected. Consider tightening quality thresholds.\")\n",
    "    \n",
    "    for dataset, stats in report['dataset_breakdown'].items():\n",
    "        if stats['removal_rate'] > 0.5:\n",
    "            report['recommendations'].append(f\"Very high removal rate for {dataset}. Review dataset-specific thresholds.\")\n",
    "        \n",
    "        # Check for class imbalance in removal\n",
    "        class_rates = [info['removal_rate'] for info in stats['class_breakdown'].values()]\n",
    "        if class_rates and max(class_rates) - min(class_rates) > 0.3:\n",
    "            report['recommendations'].append(f\"Uneven removal rates across DR classes in {dataset}. Consider class-specific adjustments.\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate comprehensive report\n",
    "if 'all_results' in locals() and all_results:\n",
    "    report = generate_identification_report(all_results)\n",
    "    print(\"Report generated successfully\")\n",
    "else:\n",
    "    print(\"Report generation skipped - no results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19275b9a-c565-4fe8-babb-ebbd65210d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save All Results\n",
    "\n",
    "# Save all identification results to files\n",
    "def save_identification_results(identifier, results, report):\n",
    "    print(\"Saving identification results\")\n",
    "   \n",
    "    # Save detailed results\n",
    "    df = pd.DataFrame(results)\n",
    "    results_file = f'{identifier.output_dir}/quality_identification_results.csv'\n",
    "    df.to_csv(results_file, index=False)\n",
    "    print(f\"  Detailed results saved: {results_file}\")\n",
    "   \n",
    "    # Save dataset profiles\n",
    "    profiles_file = f'{identifier.output_dir}/dataset_profiles.json'\n",
    "    with open(profiles_file, 'w') as f:\n",
    "        json.dump(identifier.dataset_profiles, f, indent=2)\n",
    "    print(f\"  Dataset profiles saved: {profiles_file}\")\n",
    "   \n",
    "    # Save identification report\n",
    "    report_file = f'{identifier.output_dir}/identification_report.json'\n",
    "    with open(report_file, 'w') as f:\n",
    "        json.dump(report, f, indent=2, default=str)\n",
    "    print(f\"  Analysis report saved: {report_file}\")\n",
    "   \n",
    "    # Create summary CSV for easy review\n",
    "    summary_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['recommended_action'] == 'REMOVE':\n",
    "            summary_data.append({\n",
    "                'dataset': row['dataset'],\n",
    "                'filename': row['filename'],\n",
    "                'dr_severity': row['dr_severity'],\n",
    "                'quality_score': row['overall_quality_score'],\n",
    "                'confidence': row['confidence'],\n",
    "                'reasons': ', '.join(row['removal_reasons']),\n",
    "                'image_path': row['image_path']\n",
    "            })\n",
    "   \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_file = f'{identifier.output_dir}/flagged_images_summary.csv'\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"  Flagged summary saved: {summary_file}\")\n",
    "   \n",
    "    return results_file, summary_file, profiles_file, report_file\n",
    "\n",
    "# Save all results\n",
    "if 'all_results' in locals() and 'report' in locals() and all_results:\n",
    "    results_file, summary_file, profiles_file, report_file = save_identification_results(identifier, all_results, report)\n",
    "    print(\"\\nAll results saved successfully\")\n",
    "else:\n",
    "    print(\"Results saving skipped - no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093eb262-b9c2-4028-84f2-1ab625b17f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Final Summary and Visualization\n",
    "\n",
    "# Display comprehensive final summary\n",
    "if 'all_results' in locals() and 'report' in locals() and all_results:\n",
    "    print(\"=\"*80)\n",
    "    print(\"QUALITY IDENTIFICATION COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "   \n",
    "    # Overall statistics\n",
    "    total_images = len(all_results)\n",
    "    flagged_images = len([r for r in all_results if r['recommended_action'] == 'REMOVE'])\n",
    "    removal_percentage = flagged_images / total_images * 100 if total_images > 0 else 0\n",
    "   \n",
    "    print(f\"\\nOVERALL STATISTICS:\")\n",
    "    print(f\"   Total images analyzed: {total_images:,}\")\n",
    "    print(f\"   Images flagged for removal: {flagged_images:,}\")\n",
    "    print(f\"   Overall removal rate: {removal_percentage:.1f}%\")\n",
    "   \n",
    "    # Per-dataset breakdown\n",
    "    print(f\"\\nPER-DATASET BREAKDOWN:\")\n",
    "    dataset_stats = defaultdict(lambda: {'total': 0, 'flagged': 0})\n",
    "   \n",
    "    for result in all_results:\n",
    "        dataset = result['dataset']\n",
    "        dataset_stats[dataset]['total'] += 1\n",
    "        if result['recommended_action'] == 'REMOVE':\n",
    "            dataset_stats[dataset]['flagged'] += 1\n",
    "   \n",
    "    for dataset, stats in dataset_stats.items():\n",
    "        removal_rate = stats['flagged'] / stats['total'] * 100 if stats['total'] > 0 else 0\n",
    "        print(f\"   {dataset}: {stats['flagged']:,}/{stats['total']:,} ({removal_rate:.1f}%)\")\n",
    "   \n",
    "    # Per-DR class breakdown\n",
    "    print(f\"\\nPER-DR CLASS BREAKDOWN:\")\n",
    "    dr_stats = defaultdict(lambda: {'total': 0, 'flagged': 0})\n",
    "   \n",
    "    for result in all_results:\n",
    "        dr_class = result['dr_severity']\n",
    "        dr_stats[dr_class]['total'] += 1\n",
    "        if result['recommended_action'] == 'REMOVE':\n",
    "            dr_stats[dr_class]['flagged'] += 1\n",
    "   \n",
    "    dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "    for dr_class in sorted(dr_stats.keys()):\n",
    "        stats = dr_stats[dr_class]\n",
    "        removal_rate = stats['flagged'] / stats['total'] * 100 if stats['total'] > 0 else 0\n",
    "        dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "        print(f\"   {dr_name}: {stats['flagged']:,}/{stats['total']:,} ({removal_rate:.1f}%)\")\n",
    "   \n",
    "    # Top removal reasons\n",
    "    print(f\"\\nTOP REMOVAL REASONS:\")\n",
    "    if 'removal_reasons_summary' in report:\n",
    "        sorted_reasons = sorted(report['removal_reasons_summary'].items(), key=lambda x: x[1], reverse=True)\n",
    "        for reason, count in sorted_reasons[:10]:  # Top 10 reasons\n",
    "            percentage = count / flagged_images * 100 if flagged_images > 0 else 0\n",
    "            print(f\"   {reason}: {count:,} ({percentage:.1f}% of flagged images)\")\n",
    "   \n",
    "    # Recommendations\n",
    "    if 'recommendations' in report and report['recommendations']:\n",
    "        print(f\"\\nRECOMMENDATIONS:\")\n",
    "        for i, recommendation in enumerate(report['recommendations'], 1):\n",
    "            print(f\"   {i}. {recommendation}\")\n",
    "   \n",
    "    # File locations\n",
    "    print(f\"\\nRESULTS SAVED TO:\")\n",
    "    print(f\"   Flagged images summary: {OUTPUT_DIR}/flagged_images_summary.csv\")\n",
    "    print(f\"   Detailed results: {OUTPUT_DIR}/quality_identification_results.csv\")\n",
    "    print(f\"   Analysis report: {OUTPUT_DIR}/identification_report.json\")\n",
    "    print(f\"   Sample images: {OUTPUT_DIR}/sample_images/\")\n",
    "    print(f\"   Flagged samples: {OUTPUT_DIR}/flagged_samples/\")\n",
    "   \n",
    "    print(f\"\\nNEXT STEPS:\")\n",
    "    print(f\"   1. Review flagged samples in: {OUTPUT_DIR}/flagged_samples/\")\n",
    "    print(f\"   2. Check the summary CSV for a list of all flagged images\")\n",
    "    print(f\"   3. Adjust thresholds if needed (modify dataset profiles)\")\n",
    "    print(f\"   4. Use the detailed results for actual image removal when ready\")\n",
    "   \n",
    "    print(f\"\\nQuality identification process completed successfully\")\n",
    "else:\n",
    "    print(\"No results to summarize - please run all previous cells first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe342e61-aff3-42f7-afca-69cf8f233494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Quick Visualization\n",
    "\n",
    "# Create basic visualizations for quality analysis results\n",
    "if 'all_results' in locals() and all_results:\n",
    "    print(\"Creating basic visualizations\")\n",
    "    \n",
    "    # Set up matplotlib\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('DR Dataset Quality Analysis Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # 1. Removal rates by dataset\n",
    "    ax1 = axes[0, 0]\n",
    "    dataset_removal_rates = []\n",
    "    dataset_names = []\n",
    "    \n",
    "    for dataset in df['dataset'].unique():\n",
    "        dataset_data = df[df['dataset'] == dataset]\n",
    "        removal_rate = len(dataset_data[dataset_data['recommended_action'] == 'REMOVE']) / len(dataset_data) * 100\n",
    "        dataset_removal_rates.append(removal_rate)\n",
    "        dataset_names.append(dataset)\n",
    "    \n",
    "    bars1 = ax1.bar(range(len(dataset_names)), dataset_removal_rates, color='lightcoral', alpha=0.7)\n",
    "    ax1.set_xlabel('Dataset')\n",
    "    ax1.set_ylabel('Removal Rate (%)')\n",
    "    ax1.set_title('Removal Rates by Dataset')\n",
    "    ax1.set_xticks(range(len(dataset_names)))\n",
    "    ax1.set_xticklabels(dataset_names, rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, rate in zip(bars1, dataset_removal_rates):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{rate:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Removal rates by DR class\n",
    "    ax2 = axes[0, 1]\n",
    "    dr_removal_rates = []\n",
    "    dr_labels = []\n",
    "    dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "    \n",
    "    for dr_class in sorted(df['dr_severity'].unique()):\n",
    "        dr_data = df[df['dr_severity'] == dr_class]\n",
    "        removal_rate = len(dr_data[dr_data['recommended_action'] == 'REMOVE']) / len(dr_data) * 100\n",
    "        dr_removal_rates.append(removal_rate)\n",
    "        dr_label = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "        dr_labels.append(dr_label)\n",
    "    \n",
    "    bars2 = ax2.bar(range(len(dr_labels)), dr_removal_rates, color='lightblue', alpha=0.7)\n",
    "    ax2.set_xlabel('DR Severity')\n",
    "    ax2.set_ylabel('Removal Rate (%)')\n",
    "    ax2.set_title('Removal Rates by DR Severity')\n",
    "    ax2.set_xticks(range(len(dr_labels)))\n",
    "    ax2.set_xticklabels(dr_labels, rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, rate in zip(bars2, dr_removal_rates):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{rate:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Quality score distribution\n",
    "    ax3 = axes[1, 0]\n",
    "    keep_scores = df[df['recommended_action'] == 'KEEP']['overall_quality_score']\n",
    "    remove_scores = df[df['recommended_action'] == 'REMOVE']['overall_quality_score']\n",
    "    \n",
    "    ax3.hist(keep_scores, bins=30, alpha=0.7, label='Keep', color='lightgreen', density=True)\n",
    "    ax3.hist(remove_scores, bins=30, alpha=0.7, label='Remove', color='lightcoral', density=True)\n",
    "    ax3.set_xlabel('Quality Score')\n",
    "    ax3.set_ylabel('Density')\n",
    "    ax3.set_title('Quality Score Distribution')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Top removal reasons\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'removal_reasons_summary' in report:\n",
    "        reasons = list(report['removal_reasons_summary'].keys())[:10]  # Top 10\n",
    "        counts = [report['removal_reasons_summary'][reason] for reason in reasons]\n",
    "        \n",
    "        bars4 = ax4.barh(range(len(reasons)), counts, color='orange', alpha=0.7)\n",
    "        ax4.set_ylabel('Removal Reason')\n",
    "        ax4.set_xlabel('Count')\n",
    "        ax4.set_title('Top Removal Reasons')\n",
    "        ax4.set_yticks(range(len(reasons)))\n",
    "        ax4.set_yticklabels([reason.replace('_', ' ').title() for reason in reasons])\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars4, counts):\n",
    "            width = bar.get_width()\n",
    "            ax4.text(width + max(counts)*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "                    f'{count}', ha='left', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f'{OUTPUT_DIR}/analysis_summary_plots.png'\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Visualization saved to: {plot_file}\")\n",
    "\n",
    "else:\n",
    "    print(\"Visualization creation skipped - no results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee55f3e-69d7-458f-8a35-ac29d1439a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Final Checkpoint - Verification\n",
    "\n",
    "# Final verification that all components completed successfully\n",
    "print(\"FINAL VERIFICATION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if all major components completed\n",
    "checks = {\n",
    "    'Valid datasets found': 'valid_datasets' in locals() and bool(valid_datasets),\n",
    "    'Dataset profiles created': 'dataset_profiles' in locals() and bool(dataset_profiles),\n",
    "    'Quality analysis completed': 'all_results' in locals() and bool(all_results),\n",
    "    'Report generated': 'report' in locals() and bool(report),\n",
    "    'Results saved': os.path.exists(f'{OUTPUT_DIR}/flagged_images_summary.csv'),\n",
    "    'Sample images created': os.path.exists(f'{OUTPUT_DIR}/sample_images'),\n",
    "    'Flagged samples created': os.path.exists(f'{OUTPUT_DIR}/flagged_samples')\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "for check_name, check_result in checks.items():\n",
    "    status = \"PASS\" if check_result else \"FAIL\"\n",
    "    print(f\"{status}: {check_name}\")\n",
    "    if not check_result:\n",
    "        all_good = False\n",
    "\n",
    "if all_good:\n",
    "    print(f\"\\nSUCCESS: All components completed successfully\")\n",
    "    print(f\"Check the '{OUTPUT_DIR}' directory for all results\")\n",
    "   \n",
    "    if 'all_results' in locals():\n",
    "        total = len(all_results)\n",
    "        flagged = len([r for r in all_results if r['recommended_action'] == 'REMOVE'])\n",
    "        print(f\"Final count: {flagged:,} of {total:,} images flagged for removal ({flagged/total*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: Some components did not complete successfully\")\n",
    "    print(f\"Please review the error messages above and re-run the failed sections\")\n",
    "\n",
    "print(f\"\\nIMPORTANT: This analysis only IDENTIFIED potential issues\")\n",
    "print(f\"NO IMAGES WERE ACTUALLY REMOVED from your datasets\")\n",
    "print(f\"Review the flagged samples before deciding on actual removal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Check what sample images were saved\n",
    "import os\n",
    "sample_base_dir = f'{identifier.output_dir}/sample_images'\n",
    "print(\"Sample images saved:\")\n",
    "for dataset_name in os.listdir(sample_base_dir):\n",
    "    dataset_sample_dir = os.path.join(sample_base_dir, dataset_name)\n",
    "    if os.path.isdir(dataset_sample_dir):\n",
    "        num_samples = len([f for f in os.listdir(dataset_sample_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"   {dataset_name}: {num_samples} sample images in {dataset_sample_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875afcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Problematic Images Review\n",
    "\n",
    "# Find and organize problematic images for manual review\n",
    "def find_and_review_problematic_images(identifier, dataset_profiles,\n",
    "                                     review_dir='problematic_images_review_all'):\n",
    "    \n",
    "    # Create review directory\n",
    "    os.makedirs(review_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Finding problematic images based on quality thresholds\")\n",
    "    \n",
    "    for dataset_name, profile in dataset_profiles.items():\n",
    "        print(f\"\\nProcessing {dataset_name}\")\n",
    "        \n",
    "        # Get adaptive thresholds for this dataset\n",
    "        thresholds = profile['adaptive_thresholds']\n",
    "        \n",
    "        # Create subdirectories for this dataset\n",
    "        dataset_review_dir = os.path.join(review_dir, dataset_name)\n",
    "        os.makedirs(dataset_review_dir, exist_ok=True)\n",
    "        \n",
    "        # Analyze all images in the dataset\n",
    "        dataset_path = valid_datasets[dataset_name]\n",
    "        all_images = []\n",
    "        \n",
    "        # Collect all images from ALL subdirectories (all DR severity levels)\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    all_images.append(os.path.join(root, file))\n",
    "        \n",
    "        print(f\"   Analyzing {len(all_images)} images\")\n",
    "        \n",
    "        problematic_by_severity = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "        \n",
    "        # Analyze each image\n",
    "        for i, img_path in enumerate(all_images):\n",
    "            if i % 500 == 0 and i > 0:\n",
    "                print(f\"      Progress: {i}/{len(all_images)} ({i/len(all_images)*100:.1f}%)\")\n",
    "            \n",
    "            try:\n",
    "                # Get image characteristics\n",
    "                char = identifier.analyze_single_image(img_path)\n",
    "                if not char:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate quality score (same logic as in profiling)\n",
    "                brightness = float(char['brightness']) if char['brightness'] is not None else 127.5\n",
    "                contrast = float(char['contrast']) if char['contrast'] is not None else 50.0\n",
    "                sharpness = float(char['sharpness']) if char['sharpness'] is not None else 500.0\n",
    "                entropy = float(char['entropy']) if char['entropy'] is not None else 4.0\n",
    "                illumination_uniformity = float(char['illumination_uniformity']) if char['illumination_uniformity'] is not None else 0.5\n",
    "                vessel_visibility = float(char['vessel_visibility']) if char['vessel_visibility'] is not None else 0.1\n",
    "                optic_disc_visibility = float(char['optic_disc_visibility']) if char['optic_disc_visibility'] is not None else 0.1\n",
    "                \n",
    "                # Normalize metrics\n",
    "                brightness_norm = min(1.0, max(0.0, brightness / 255.0))\n",
    "                contrast_norm = min(1.0, max(0.0, contrast / 100.0))\n",
    "                sharpness_norm = min(1.0, max(0.0, sharpness / 1000.0))\n",
    "                entropy_norm = min(1.0, max(0.0, entropy / 8.0))\n",
    "                \n",
    "                basic_quality = np.mean([brightness_norm, contrast_norm, sharpness_norm, entropy_norm])\n",
    "                medical_quality = np.mean([\n",
    "                    illumination_uniformity,\n",
    "                    min(1.0, vessel_visibility * 10),\n",
    "                    min(1.0, optic_disc_visibility * 10)\n",
    "                ])\n",
    "                \n",
    "                combined_quality = 0.3 * basic_quality + 0.7 * medical_quality\n",
    "                \n",
    "                # Determine DR severity from path or filename\n",
    "                dr_severity = get_dr_severity_from_path(img_path)\n",
    "                \n",
    "                # Check if image is below threshold for its DR severity\n",
    "                if dr_severity in thresholds and combined_quality < thresholds[dr_severity]:\n",
    "                    problematic_by_severity[dr_severity].append({\n",
    "                        'path': img_path,\n",
    "                        'quality_score': combined_quality,\n",
    "                        'threshold': thresholds[dr_severity],\n",
    "                        'characteristics': char\n",
    "                    })\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"      Error analyzing {img_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Save problematic images by severity\n",
    "        total_problematic = 0\n",
    "        for severity, images in problematic_by_severity.items():\n",
    "            if images:\n",
    "                severity_dir = os.path.join(dataset_review_dir, f'DR_severity_{severity}')\n",
    "                os.makedirs(severity_dir, exist_ok=True)\n",
    "                \n",
    "                # Sort by quality score (worst first)\n",
    "                images.sort(key=lambda x: x['quality_score'])\n",
    "                \n",
    "                print(f\"   DR Severity {severity}: {len(images)} problematic images\")\n",
    "                \n",
    "                # Copy worst 50 images for manual review\n",
    "                for i, img_info in enumerate(images[:50]):\n",
    "                    try:\n",
    "                        src_path = img_info['path']\n",
    "                        dst_name = f\"quality_{img_info['quality_score']:.3f}_{os.path.basename(src_path)}\"\n",
    "                        dst_path = os.path.join(severity_dir, dst_name)\n",
    "                        shutil.copy2(src_path, dst_path)\n",
    "                        \n",
    "                        # Save characteristics as text file\n",
    "                        txt_path = dst_path.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
    "                        with open(txt_path, 'w') as f:\n",
    "                            f.write(f\"Quality Score: {img_info['quality_score']:.3f}\\n\")\n",
    "                            f.write(f\"Threshold: {img_info['threshold']:.3f}\\n\")\n",
    "                            f.write(f\"Original Path: {src_path}\\n\\n\")\n",
    "                            f.write(\"Characteristics:\\n\")\n",
    "                            for key, value in img_info['characteristics'].items():\n",
    "                                f.write(f\"  {key}: {value}\\n\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"      Error copying {src_path}: {e}\")\n",
    "                \n",
    "                total_problematic += len(images)\n",
    "        \n",
    "        print(f\"   Found {total_problematic} total problematic images in {dataset_name}\")\n",
    "        print(f\"   Review images saved to: {dataset_review_dir}\")\n",
    "    \n",
    "    print(f\"\\nReview complete. Check the '{review_dir}' directory\")\n",
    "\n",
    "# Extract DR severity from image path or filename\n",
    "def get_dr_severity_from_path(img_path):\n",
    "    import re\n",
    "    path_lower = img_path.lower()\n",
    "    \n",
    "    # First, check for direct folder patterns like /0/, /1/, /2/, /3/, /4/\n",
    "    folder_match = re.search(r'[/\\\\]([0-4])[/\\\\]', img_path)\n",
    "    if folder_match:\n",
    "        return int(folder_match.group(1))\n",
    "    \n",
    "    # Check for keyword-based patterns\n",
    "    if 'no_dr' in path_lower or 'grade_0' in path_lower or '_0_' in path_lower:\n",
    "        return 0\n",
    "    elif 'mild' in path_lower or 'grade_1' in path_lower or '_1_' in path_lower:\n",
    "        return 1\n",
    "    elif 'moderate' in path_lower or 'grade_2' in path_lower or '_2_' in path_lower:\n",
    "        return 2\n",
    "    elif 'severe' in path_lower or 'grade_3' in path_lower or '_3_' in path_lower:\n",
    "        return 3\n",
    "    elif 'proliferative' in path_lower or 'grade_4' in path_lower or '_4_' in path_lower:\n",
    "        return 4\n",
    "    \n",
    "    # Look for patterns like \"grade_2\", \"severity_1\", etc.\n",
    "    grade_match = re.search(r'grade[_\\-]?([0-4])', path_lower)\n",
    "    if grade_match:\n",
    "        return int(grade_match.group(1))\n",
    "    \n",
    "    severity_match = re.search(r'severity[_\\-]?([0-4])', path_lower)\n",
    "    if severity_match:\n",
    "        return int(severity_match.group(1))\n",
    "    \n",
    "    # Look for numeric patterns in filename\n",
    "    filename_match = re.search(r'[_\\-]([0-4])[_\\-\\.]', path_lower)\n",
    "    if filename_match:\n",
    "        return int(filename_match.group(1))\n",
    "    \n",
    "    # Default to 0 if can't determine\n",
    "    print(f\"   Could not determine DR severity for: {img_path}\")\n",
    "    return 0\n",
    "\n",
    "# Create an HTML file for easy image review\n",
    "def create_review_html(review_dir='problematic_images_review_all'):\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Problematic Images Review</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "            .dataset { margin-bottom: 30px; border: 1px solid #ccc; padding: 15px; }\n",
    "            .severity { margin-bottom: 20px; }\n",
    "            .image-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 10px; }\n",
    "            .image-item { border: 1px solid #ddd; padding: 10px; text-align: center; }\n",
    "            .image-item img { max-width: 100%; height: 150px; object-fit: cover; }\n",
    "            .quality-score { font-weight: bold; color: red; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Problematic Images Review</h1>\n",
    "    \"\"\"\n",
    "    \n",
    "    for dataset_name in os.listdir(review_dir):\n",
    "        dataset_path = os.path.join(review_dir, dataset_name)\n",
    "        if not os.path.isdir(dataset_path):\n",
    "            continue\n",
    "        \n",
    "        html_content += f'<div class=\"dataset\"><h2>{dataset_name}</h2>'\n",
    "        \n",
    "        for severity_dir in sorted(os.listdir(dataset_path)):\n",
    "            severity_path = os.path.join(dataset_path, severity_dir)\n",
    "            if not os.path.isdir(severity_path):\n",
    "                continue\n",
    "            \n",
    "            html_content += f'<div class=\"severity\"><h3>{severity_dir}</h3><div class=\"image-grid\">'\n",
    "            \n",
    "            images = [f for f in os.listdir(severity_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            for img_file in sorted(images)[:20]:  # Show first 20\n",
    "                quality_score = img_file.split('_')[1] if '_' in img_file else 'unknown'\n",
    "                img_rel_path = os.path.join(dataset_name, severity_dir, img_file).replace('\\\\', '/')\n",
    "                \n",
    "                html_content += f'''\n",
    "                <div class=\"image-item\">\n",
    "                    <img src=\"{img_rel_path}\" alt=\"{img_file}\">\n",
    "                    <div class=\"quality-score\">Quality: {quality_score}</div>\n",
    "                    <div>{img_file}</div>\n",
    "                </div>\n",
    "                '''\n",
    "            \n",
    "            html_content += '</div></div>'\n",
    "        \n",
    "        html_content += '</div>'\n",
    "    \n",
    "    html_content += '</body></html>'\n",
    "    \n",
    "    html_path = os.path.join(review_dir, 'review.html')\n",
    "    with open(html_path, 'w') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"HTML review file created: {html_path}\")\n",
    "    print(\"   Open this file in your web browser to easily review problematic images\")\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting problematic image identification\")\n",
    "find_and_review_problematic_images(identifier, dataset_profiles)\n",
    "\n",
    "# Create HTML review file\n",
    "create_review_html()\n",
    "\n",
    "print(\"\\nReview setup complete\")\n",
    "print(\"\\nTo review the images:\")\n",
    "print(\"1. Check the 'problematic_images_review_all' directory\")\n",
    "print(\"2. Open 'problematic_images_review_all/review.html' in your web browser\")\n",
    "print(\"3. Each image has a quality score and characteristics file (.txt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Manual Threshold Adjustment (Optional)\n",
    "\n",
    "print(\"MANUAL THRESHOLD ADJUSTMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Use this cell to fine-tune removal thresholds for each dataset\")\n",
    "print(\"Lower thresholds = more images flagged for removal\")\n",
    "print(\"Higher thresholds = fewer images flagged for removal\")\n",
    "print(\"Current thresholds are based on your dataset analysis\")\n",
    "\n",
    "# Check if dataset_profiles exists\n",
    "if 'dataset_profiles' not in locals() or not dataset_profiles:\n",
    "    print(\"\\nERROR: Dataset profiles not found\")\n",
    "    print(\"Please run the previous cells first to create dataset profiles.\")\n",
    "    print(\"Required steps:\")\n",
    "    print(\"1. Run dataset validation (Cell 3)\")\n",
    "    print(\"2. Run dataset characterization (Cell 6)\")\n",
    "    print(\"3. Then come back to this cell\")\n",
    "else:\n",
    "    # Display current thresholds\n",
    "    print(\"\\nCURRENT THRESHOLDS:\")\n",
    "    for dataset_name, profile in dataset_profiles.items():\n",
    "        print(f\"\\n{dataset_name}:\")\n",
    "        for dr_class, threshold in profile['adaptive_thresholds'].items():\n",
    "            dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "            dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "            print(f\"  {dr_name} (Class {dr_class}): {threshold:.3f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"MANUAL ADJUSTMENT SECTION\")\n",
    "    print(\"Edit the values below to adjust thresholds\")\n",
    "    print(\"Set to None to keep current value\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Manual threshold override dictionary\n",
    "    # Users can edit these values\n",
    "    manual_thresholds = {\n",
    "        'APTOS2019': {\n",
    "            0: None,  # No DR - set to None to keep current, or set value like 0.250\n",
    "            1: None,  # Mild DR\n",
    "            2: None,  # Moderate DR  \n",
    "            3: None,  # Severe DR\n",
    "            4: None   # Proliferative DR\n",
    "        },\n",
    "        'Diabetic_Retinopathy_V03': {\n",
    "            0: None,\n",
    "            1: None,\n",
    "            2: None,\n",
    "            3: None,\n",
    "            4: None\n",
    "        },\n",
    "        'IDRiD': {\n",
    "            0: None,\n",
    "            1: None,\n",
    "            2: None,\n",
    "            3: None,\n",
    "            4: None\n",
    "        },\n",
    "        'Messidor2': {\n",
    "            0: None,\n",
    "            1: None,\n",
    "            2: None,\n",
    "            3: None,\n",
    "            4: None\n",
    "        },\n",
    "        'SUSTech_SYSU': {\n",
    "            0: None,\n",
    "            1: None,\n",
    "            2: None,\n",
    "            3: None,\n",
    "            4: None\n",
    "        },\n",
    "        'DeepDRiD': {\n",
    "            0: None,\n",
    "            1: None,\n",
    "            2: None,\n",
    "            3: None,\n",
    "            4: None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Apply manual overrides\n",
    "    updated_profiles = {}\n",
    "    changes_made = False\n",
    "\n",
    "    for dataset_name, profile in dataset_profiles.items():\n",
    "        updated_profiles[dataset_name] = profile.copy()\n",
    "        updated_profiles[dataset_name]['adaptive_thresholds'] = profile['adaptive_thresholds'].copy()\n",
    "        \n",
    "        if dataset_name in manual_thresholds:\n",
    "            for dr_class, manual_threshold in manual_thresholds[dataset_name].items():\n",
    "                if manual_threshold is not None:\n",
    "                    old_threshold = profile['adaptive_thresholds'][dr_class]\n",
    "                    updated_profiles[dataset_name]['adaptive_thresholds'][dr_class] = manual_threshold\n",
    "                    changes_made = True\n",
    "                    dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "                    dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "                    print(f\"Updated {dataset_name} - {dr_name}: {old_threshold:.3f} → {manual_threshold:.3f}\")\n",
    "\n",
    "    if changes_made:\n",
    "        print(f\"\\nThreshold adjustments applied\")\n",
    "        print(\"Updated profiles will be used for final dataset creation.\")\n",
    "        # Update the global profiles\n",
    "        dataset_profiles = updated_profiles\n",
    "    else:\n",
    "        print(f\"\\nNo manual adjustments made. Using original thresholds\")\n",
    "\n",
    "    print(f\"\\nFINAL THRESHOLDS AFTER ADJUSTMENT:\")\n",
    "    for dataset_name, profile in dataset_profiles.items():\n",
    "        print(f\"\\n{dataset_name}:\")\n",
    "        for dr_class, threshold in profile['adaptive_thresholds'].items():\n",
    "            dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "            dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "            print(f\"  {dr_name} (Class {dr_class}): {threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97871da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Create Cleaned Datasets\n",
    "\n",
    "# Create cleaned datasets\n",
    "def create_cleaned_dataset(source_datasets, profiles, \n",
    "                          copy_output_dir='DREAM_dataset_cleaned'):\n",
    "    \n",
    "    print(\"CREATING CLEANED DATASETS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Output directory: {copy_output_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create base output directory\n",
    "    os.makedirs(copy_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Statistics tracking\n",
    "    copy_stats = {\n",
    "        'total_processed': 0, 'total_kept': 0, 'total_removed': 0,\n",
    "        'by_dataset': {}, 'by_dr_class': {i: {'kept': 0, 'removed': 0} for i in range(5)}\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset_name, dataset_path in source_datasets.items():\n",
    "        print(f\"\\nProcessing {dataset_name}\")\n",
    "        \n",
    "        if dataset_name not in profiles:\n",
    "            print(f\"   No profile found for {dataset_name}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        profile = profiles[dataset_name]\n",
    "        thresholds = profile['adaptive_thresholds']\n",
    "        \n",
    "        # Create dataset output directory\n",
    "        copy_dataset_dir = os.path.join(copy_output_dir, dataset_name)\n",
    "        os.makedirs(copy_dataset_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize dataset stats\n",
    "        copy_dataset_stats = {\n",
    "            'total_processed': 0, 'total_kept': 0, 'total_removed': 0,\n",
    "            'by_dr_class': {i: {'kept': 0, 'removed': 0} for i in range(5)}\n",
    "        }\n",
    "        \n",
    "        # Process each DR class folder\n",
    "        for dr_class in range(5):\n",
    "            dr_class_path = os.path.join(dataset_path, str(dr_class))\n",
    "            \n",
    "            if not os.path.exists(dr_class_path):\n",
    "                print(f\"   DR class {dr_class} folder not found, skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Create output DR class directory\n",
    "            copy_dr_dir = os.path.join(copy_dataset_dir, str(dr_class))\n",
    "            os.makedirs(copy_dr_dir, exist_ok=True)\n",
    "            \n",
    "            # Get all images in this DR class\n",
    "            image_files = []\n",
    "            for file in os.listdir(dr_class_path):\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff', '.bmp')):\n",
    "                    image_files.append(file)\n",
    "            \n",
    "            print(f\"   DR Class {dr_class}: Found {len(image_files)} images\")\n",
    "            \n",
    "            threshold = thresholds.get(dr_class, 0.3)\n",
    "            \n",
    "            kept_count = 0\n",
    "            removed_count = 0\n",
    "            \n",
    "            # Process each image\n",
    "            for i, image_file in enumerate(image_files):\n",
    "                if i % 500 == 0 and i > 0:\n",
    "                    print(f\"      Progress: {i}/{len(image_files)} ({i/len(image_files)*100:.1f}%)\")\n",
    "                \n",
    "                try:\n",
    "                    source_image_path = os.path.join(dr_class_path, image_file)\n",
    "                    \n",
    "                    # Analyze image quality\n",
    "                    char = identifier.analyze_single_image(source_image_path)\n",
    "                    if not char:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate quality score (same logic as before)\n",
    "                    brightness = float(char['brightness']) if char['brightness'] is not None else 127.5\n",
    "                    contrast = float(char['contrast']) if char['contrast'] is not None else 50.0\n",
    "                    sharpness = float(char['sharpness']) if char['sharpness'] is not None else 500.0\n",
    "                    entropy = float(char['entropy']) if char['entropy'] is not None else 4.0\n",
    "                    illumination_uniformity = float(char['illumination_uniformity']) if char['illumination_uniformity'] is not None else 0.5\n",
    "                    vessel_visibility = float(char['vessel_visibility']) if char['vessel_visibility'] is not None else 0.1\n",
    "                    optic_disc_visibility = float(char['optic_disc_visibility']) if char['optic_disc_visibility'] is not None else 0.1\n",
    "                    \n",
    "                    # Normalize metrics\n",
    "                    brightness_norm = min(1.0, max(0.0, brightness / 255.0))\n",
    "                    contrast_norm = min(1.0, max(0.0, contrast / 100.0))\n",
    "                    sharpness_norm = min(1.0, max(0.0, sharpness / 1000.0))\n",
    "                    entropy_norm = min(1.0, max(0.0, entropy / 8.0))\n",
    "                    \n",
    "                    basic_quality = np.mean([brightness_norm, contrast_norm, sharpness_norm, entropy_norm])\n",
    "                    medical_quality = np.mean([\n",
    "                        illumination_uniformity,\n",
    "                        min(1.0, vessel_visibility * 10),\n",
    "                        min(1.0, optic_disc_visibility * 10)\n",
    "                    ])\n",
    "                    \n",
    "                    combined_quality = 0.3 * basic_quality + 0.7 * medical_quality\n",
    "                    \n",
    "                    # Decide whether to keep or remove\n",
    "                    if combined_quality >= threshold:\n",
    "                        # Keep the image - create copy\n",
    "                        copy_dest_path = os.path.join(copy_dr_dir, image_file)\n",
    "                        shutil.copy2(source_image_path, copy_dest_path)\n",
    "                        \n",
    "                        kept_count += 1\n",
    "                        copy_dataset_stats['by_dr_class'][dr_class]['kept'] += 1\n",
    "                        copy_stats['by_dr_class'][dr_class]['kept'] += 1\n",
    "                        \n",
    "                    else:\n",
    "                        # Remove the image - don't copy\n",
    "                        removed_count += 1\n",
    "                        copy_dataset_stats['by_dr_class'][dr_class]['removed'] += 1\n",
    "                        copy_stats['by_dr_class'][dr_class]['removed'] += 1\n",
    "                    \n",
    "                    copy_dataset_stats['total_processed'] += 1\n",
    "                    copy_stats['total_processed'] += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      Error processing {image_file}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Update stats\n",
    "            copy_dataset_stats['total_kept'] += kept_count\n",
    "            copy_dataset_stats['total_removed'] += removed_count\n",
    "            \n",
    "            dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "            dr_name = dr_names[dr_class] if 0 <= dr_class < 5 else f'Class {dr_class}'\n",
    "            removal_rate = (removed_count / (kept_count + removed_count) * 100) if (kept_count + removed_count) > 0 else 0\n",
    "            \n",
    "            print(f\"      {dr_name}: Kept {kept_count}, Removed {removed_count} ({removal_rate:.1f}% removal)\")\n",
    "        \n",
    "        # Update total stats\n",
    "        copy_stats['total_kept'] += copy_dataset_stats['total_kept']\n",
    "        copy_stats['total_removed'] += copy_dataset_stats['total_removed']\n",
    "        copy_stats['by_dataset'][dataset_name] = copy_dataset_stats\n",
    "        \n",
    "        dataset_removal_rate = (copy_dataset_stats['total_removed'] / copy_dataset_stats['total_processed'] * 100) if copy_dataset_stats['total_processed'] > 0 else 0\n",
    "        \n",
    "        print(f\"   {dataset_name} Summary:\")\n",
    "        print(f\"      Total processed: {copy_dataset_stats['total_processed']:,}\")\n",
    "        print(f\"      Kept: {copy_dataset_stats['total_kept']:,}\")\n",
    "        print(f\"      Removed: {copy_dataset_stats['total_removed']:,} ({dataset_removal_rate:.1f}%)\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    # Save statistics\n",
    "    copy_stats_file = os.path.join(copy_output_dir, 'cleaning_statistics.json')\n",
    "    \n",
    "    with open(copy_stats_file, 'w') as f:\n",
    "        json.dump(copy_stats, f, indent=2)\n",
    "    \n",
    "    # Create summary report\n",
    "    create_cleaning_summary_report(copy_stats, copy_output_dir, processing_time)\n",
    "    \n",
    "    return copy_stats, processing_time\n",
    "\n",
    "# Create a human-readable summary report\n",
    "def create_cleaning_summary_report(stats, output_dir, processing_time):\n",
    "    \n",
    "    report_file = os.path.join(output_dir, 'CLEANING_SUMMARY.txt')\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(f\"DREAM DATASET CLEANING SUMMARY\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "        f.write(f\"Cleaning completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Processing time: {processing_time/60:.1f} minutes\\n\\n\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        total_processed = stats['total_processed']\n",
    "        total_kept = stats['total_kept']\n",
    "        total_removed = stats['total_removed']\n",
    "        overall_removal_rate = (total_removed / total_processed * 100) if total_processed > 0 else 0\n",
    "        \n",
    "        f.write(\"OVERALL STATISTICS:\\n\")\n",
    "        f.write(f\"  Total images processed: {total_processed:,}\\n\")\n",
    "        f.write(f\"  Images kept: {total_kept:,}\\n\")\n",
    "        f.write(f\"  Images removed: {total_removed:,}\\n\")\n",
    "        f.write(f\"  Overall removal rate: {overall_removal_rate:.1f}%\\n\\n\")\n",
    "        \n",
    "        # Per-dataset statistics\n",
    "        f.write(\"PER-DATASET STATISTICS:\\n\")\n",
    "        for dataset_name, dataset_stats in stats['by_dataset'].items():\n",
    "            removal_rate = (dataset_stats['total_removed'] / dataset_stats['total_processed'] * 100) if dataset_stats['total_processed'] > 0 else 0\n",
    "            f.write(f\"\\n  {dataset_name}:\\n\")\n",
    "            f.write(f\"    Processed: {dataset_stats['total_processed']:,}\\n\")\n",
    "            f.write(f\"    Kept: {dataset_stats['total_kept']:,}\\n\")\n",
    "            f.write(f\"    Removed: {dataset_stats['total_removed']:,} ({removal_rate:.1f}%)\\n\")\n",
    "        \n",
    "        # Per-DR class statistics\n",
    "        f.write(\"\\nPER-DR CLASS STATISTICS:\\n\")\n",
    "        dr_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "        for dr_class in range(5):\n",
    "            dr_stats = stats['by_dr_class'][dr_class]\n",
    "            total_dr = dr_stats['kept'] + dr_stats['removed']\n",
    "            removal_rate = (dr_stats['removed'] / total_dr * 100) if total_dr > 0 else 0\n",
    "            dr_name = dr_names[dr_class]\n",
    "            \n",
    "            f.write(f\"\\n  {dr_name} (Class {dr_class}):\\n\")\n",
    "            f.write(f\"    Total: {total_dr:,}\\n\")\n",
    "            f.write(f\"    Kept: {dr_stats['kept']:,}\\n\")\n",
    "            f.write(f\"    Removed: {dr_stats['removed']:,} ({removal_rate:.1f}%)\\n\")\n",
    "        \n",
    "        f.write(f\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "        f.write(\"NOTE: This cleaning was based on automated quality analysis.\\n\")\n",
    "        f.write(\"Manual review of results is recommended before using for training.\\n\")\n",
    "        f.write(\"\\nComplete independent dataset copy created.\\n\")\n",
    "        f.write(\"Safe to use even if original dataset is moved/deleted.\\n\")\n",
    "\n",
    "# Run the cleaning process\n",
    "print(\"Starting dataset cleaning process\")\n",
    "print(\"This may take a while depending on dataset size\\n\")\n",
    "\n",
    "# Create cleaned dataset\n",
    "final_stats, total_processing_time = create_cleaned_dataset(\n",
    "    valid_datasets, dataset_profiles\n",
    ")\n",
    "\n",
    "print(f\"\\nDATASET CLEANING COMPLETE\")\n",
    "\n",
    "print(f\"\\nSTATISTICS:\")\n",
    "print(f\"   Location: DREAM_dataset_cleaned/\")\n",
    "print(f\"   Total images processed: {final_stats['total_processed']:,}\")\n",
    "print(f\"   Images kept: {final_stats['total_kept']:,}\")\n",
    "print(f\"   Images removed: {final_stats['total_removed']:,}\")\n",
    "removal_rate = (final_stats['total_removed'] / final_stats['total_processed'] * 100) if final_stats['total_processed'] > 0 else 0\n",
    "print(f\"   Overall removal rate: {removal_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\nRESULTS SAVED TO:\")\n",
    "print(f\"   Cleaned dataset: DREAM_dataset_cleaned/\")\n",
    "print(f\"   Detailed statistics: DREAM_dataset_cleaned/cleaning_statistics.json\")\n",
    "print(f\"   Readable summary: DREAM_dataset_cleaned/CLEANING_SUMMARY.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
